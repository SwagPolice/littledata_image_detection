{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras version:2.0.5\n",
      "tensorflow version:1.1.0\n",
      "Found 3221 images belonging to 8 classes.\n",
      "Found 446 images belonging to 8 classes.\n",
      "Epoch 1/80\n",
      "200/200 [==============================] - 534s - loss: 1.4966 - acc: 0.4584 - val_loss: 0.8381 - val_acc: 0.7601\n",
      "Epoch 2/80\n",
      "200/200 [==============================] - 378s - loss: 0.9810 - acc: 0.6672 - val_loss: 0.6020 - val_acc: 0.8466\n",
      "Epoch 3/80\n",
      "200/200 [==============================] - 379s - loss: 0.8214 - acc: 0.7216 - val_loss: 0.5014 - val_acc: 0.8686\n",
      "Epoch 4/80\n",
      "200/200 [==============================] - 375s - loss: 0.6818 - acc: 0.7726 - val_loss: 0.4003 - val_acc: 0.8897\n",
      "Epoch 5/80\n",
      "200/200 [==============================] - 375s - loss: 0.6187 - acc: 0.7923 - val_loss: 0.5620 - val_acc: 0.8332\n",
      "Epoch 6/80\n",
      "200/200 [==============================] - 383s - loss: 0.5647 - acc: 0.8079 - val_loss: 0.3463 - val_acc: 0.8937\n",
      "Epoch 7/80\n",
      "200/200 [==============================] - 380s - loss: 0.5538 - acc: 0.8157 - val_loss: 0.3808 - val_acc: 0.8924\n",
      "Epoch 8/80\n",
      "200/200 [==============================] - 376s - loss: 0.4926 - acc: 0.8379 - val_loss: 0.4063 - val_acc: 0.8830\n",
      "Epoch 9/80\n",
      "200/200 [==============================] - 374s - loss: 0.4931 - acc: 0.8353 - val_loss: 0.6504 - val_acc: 0.8305\n",
      "Epoch 10/80\n",
      "200/200 [==============================] - 373s - loss: 0.4908 - acc: 0.8421 - val_loss: 0.2839 - val_acc: 0.9152\n",
      "Epoch 11/80\n",
      "200/200 [==============================] - 375s - loss: 0.4839 - acc: 0.8429 - val_loss: 0.3576 - val_acc: 0.9166\n",
      "Epoch 12/80\n",
      "200/200 [==============================] - 372s - loss: 0.4496 - acc: 0.8564 - val_loss: 0.3725 - val_acc: 0.9166\n",
      "Epoch 13/80\n",
      "200/200 [==============================] - 370s - loss: 0.4650 - acc: 0.8508 - val_loss: 0.3444 - val_acc: 0.8924\n",
      "Epoch 14/80\n",
      "200/200 [==============================] - 435s - loss: 0.4552 - acc: 0.8544 - val_loss: 0.3948 - val_acc: 0.8843\n",
      "Epoch 15/80\n",
      "200/200 [==============================] - 399s - loss: 0.4451 - acc: 0.8538 - val_loss: 0.3527 - val_acc: 0.9197\n",
      "Epoch 16/80\n",
      "200/200 [==============================] - 384s - loss: 0.4450 - acc: 0.8578 - val_loss: 0.4226 - val_acc: 0.8879\n",
      "Epoch 17/80\n",
      "200/200 [==============================] - 386s - loss: 0.4473 - acc: 0.8622 - val_loss: 0.3736 - val_acc: 0.9058\n",
      "Epoch 18/80\n",
      "200/200 [==============================] - 394s - loss: 0.4828 - acc: 0.8489 - val_loss: 0.4234 - val_acc: 0.9170\n",
      "Epoch 19/80\n",
      "200/200 [==============================] - 393s - loss: 0.4828 - acc: 0.8437 - val_loss: 0.5429 - val_acc: 0.8677\n",
      "Epoch 20/80\n",
      "200/200 [==============================] - 393s - loss: 0.4764 - acc: 0.8528 - val_loss: 0.3644 - val_acc: 0.9000\n",
      "Epoch 21/80\n",
      "200/200 [==============================] - 390s - loss: 0.4880 - acc: 0.8456 - val_loss: 0.4986 - val_acc: 0.8413\n",
      "Epoch 22/80\n",
      "200/200 [==============================] - 389s - loss: 0.4849 - acc: 0.8507 - val_loss: 0.4075 - val_acc: 0.8870\n",
      "Epoch 23/80\n",
      "200/200 [==============================] - 392s - loss: 0.4930 - acc: 0.8461 - val_loss: 0.5528 - val_acc: 0.8700\n",
      "Epoch 24/80\n",
      "200/200 [==============================] - 392s - loss: 0.4900 - acc: 0.8478 - val_loss: 0.3920 - val_acc: 0.8812\n",
      "Epoch 25/80\n",
      "200/200 [==============================] - 448s - loss: 0.5253 - acc: 0.8387 - val_loss: 0.4896 - val_acc: 0.9036\n",
      "Epoch 26/80\n",
      "200/200 [==============================] - 441s - loss: 0.5078 - acc: 0.8451 - val_loss: 0.5168 - val_acc: 0.8659\n",
      "Epoch 27/80\n",
      "200/200 [==============================] - 429s - loss: 0.5028 - acc: 0.8429 - val_loss: 0.5474 - val_acc: 0.9000\n",
      "Epoch 28/80\n",
      "200/200 [==============================] - 400s - loss: 0.5204 - acc: 0.8409 - val_loss: 0.5002 - val_acc: 0.8879\n",
      "Epoch 29/80\n",
      "200/200 [==============================] - 415s - loss: 0.5621 - acc: 0.8373 - val_loss: 0.3978 - val_acc: 0.9197\n",
      "Epoch 30/80\n",
      "200/200 [==============================] - 400s - loss: 0.5466 - acc: 0.8333 - val_loss: 0.3897 - val_acc: 0.9040\n",
      "Epoch 31/80\n",
      "200/200 [==============================] - 389s - loss: 0.5888 - acc: 0.8252 - val_loss: 0.3921 - val_acc: 0.8901\n",
      "Epoch 32/80\n",
      "200/200 [==============================] - 390s - loss: 0.5128 - acc: 0.8446 - val_loss: 0.4449 - val_acc: 0.8780\n",
      "Epoch 33/80\n",
      "200/200 [==============================] - 391s - loss: 0.5508 - acc: 0.8413 - val_loss: 0.3812 - val_acc: 0.9094\n",
      "Epoch 34/80\n",
      "200/200 [==============================] - 391s - loss: 0.5579 - acc: 0.8394 - val_loss: 0.5044 - val_acc: 0.8525\n",
      "Epoch 35/80\n",
      "200/200 [==============================] - 393s - loss: 0.5164 - acc: 0.8458 - val_loss: 0.4103 - val_acc: 0.8978\n",
      "Epoch 36/80\n",
      "200/200 [==============================] - 395s - loss: 0.5358 - acc: 0.8340 - val_loss: 0.5485 - val_acc: 0.8359\n",
      "Epoch 37/80\n",
      "200/200 [==============================] - 392s - loss: 0.5982 - acc: 0.8340 - val_loss: 0.3698 - val_acc: 0.9036\n",
      "Epoch 38/80\n",
      "200/200 [==============================] - 390s - loss: 0.5545 - acc: 0.8340 - val_loss: 0.3932 - val_acc: 0.8942\n",
      "Epoch 39/80\n",
      "200/200 [==============================] - 390s - loss: 0.6153 - acc: 0.8280 - val_loss: 0.8459 - val_acc: 0.7229\n",
      "Epoch 40/80\n",
      "200/200 [==============================] - 393s - loss: 0.5924 - acc: 0.8278 - val_loss: 0.5747 - val_acc: 0.9022\n",
      "Epoch 41/80\n",
      "200/200 [==============================] - 390s - loss: 0.6314 - acc: 0.8124 - val_loss: 0.4218 - val_acc: 0.9108\n",
      "Epoch 42/80\n",
      "200/200 [==============================] - 393s - loss: 0.5688 - acc: 0.8316 - val_loss: 0.6280 - val_acc: 0.8735\n",
      "Epoch 43/80\n",
      "200/200 [==============================] - 401s - loss: 0.5970 - acc: 0.8298 - val_loss: 0.3696 - val_acc: 0.8991\n",
      "Epoch 44/80\n",
      "200/200 [==============================] - 445s - loss: 0.6203 - acc: 0.8192 - val_loss: 0.5071 - val_acc: 0.8803\n",
      "Epoch 45/80\n",
      "200/200 [==============================] - 514s - loss: 0.6066 - acc: 0.8152 - val_loss: 0.4696 - val_acc: 0.8709\n",
      "Epoch 46/80\n",
      "200/200 [==============================] - 373s - loss: 0.5947 - acc: 0.8350 - val_loss: 0.7322 - val_acc: 0.8408\n",
      "Epoch 47/80\n",
      "200/200 [==============================] - 373s - loss: 0.6034 - acc: 0.8167 - val_loss: 0.3603 - val_acc: 0.8874\n",
      "Epoch 48/80\n",
      "200/200 [==============================] - 375s - loss: 0.6910 - acc: 0.8085 - val_loss: 0.5901 - val_acc: 0.8408\n",
      "Epoch 49/80\n",
      "200/200 [==============================] - 371s - loss: 0.6961 - acc: 0.8015 - val_loss: 0.4755 - val_acc: 0.8610\n",
      "Epoch 50/80\n",
      "200/200 [==============================] - 369s - loss: 0.6402 - acc: 0.8207 - val_loss: 0.4857 - val_acc: 0.8350\n",
      "Epoch 51/80\n",
      "200/200 [==============================] - 434s - loss: 0.6332 - acc: 0.8139 - val_loss: 0.5205 - val_acc: 0.8659\n",
      "Epoch 52/80\n",
      "200/200 [==============================] - 468s - loss: 0.6446 - acc: 0.8181 - val_loss: 0.4186 - val_acc: 0.9121\n",
      "Epoch 53/80\n",
      "200/200 [==============================] - 483s - loss: 0.6935 - acc: 0.8020 - val_loss: 0.5016 - val_acc: 0.9108\n",
      "Epoch 54/80\n",
      "200/200 [==============================] - 504s - loss: 0.6274 - acc: 0.8183 - val_loss: 0.8133 - val_acc: 0.8547\n",
      "Epoch 55/80\n",
      "200/200 [==============================] - 424s - loss: 0.6692 - acc: 0.8070 - val_loss: 0.6197 - val_acc: 0.7982\n",
      "Epoch 56/80\n",
      "200/200 [==============================] - 527s - loss: 0.6973 - acc: 0.8099 - val_loss: 0.5542 - val_acc: 0.8516\n",
      "Epoch 57/80\n",
      "200/200 [==============================] - 461s - loss: 0.7072 - acc: 0.7951 - val_loss: 1.0594 - val_acc: 0.8018\n",
      "Epoch 58/80\n",
      "200/200 [==============================] - 404s - loss: 0.6727 - acc: 0.8030 - val_loss: 1.2645 - val_acc: 0.7103\n",
      "Epoch 59/80\n",
      "200/200 [==============================] - 413s - loss: 0.7098 - acc: 0.7998 - val_loss: 0.6783 - val_acc: 0.8570\n",
      "Epoch 60/80\n",
      "200/200 [==============================] - 426s - loss: 0.7322 - acc: 0.7944 - val_loss: 0.8256 - val_acc: 0.7350\n",
      "Epoch 61/80\n",
      "200/200 [==============================] - 453s - loss: 0.7495 - acc: 0.7803 - val_loss: 0.5555 - val_acc: 0.8946\n",
      "Epoch 62/80\n",
      "200/200 [==============================] - 435s - loss: 0.7485 - acc: 0.7935 - val_loss: 0.7179 - val_acc: 0.8233\n",
      "Epoch 63/80\n",
      "200/200 [==============================] - 565s - loss: 0.8119 - acc: 0.7741 - val_loss: 0.4525 - val_acc: 0.8901\n",
      "Epoch 64/80\n",
      "200/200 [==============================] - 399s - loss: 0.7377 - acc: 0.7867 - val_loss: 0.5250 - val_acc: 0.8260\n",
      "Epoch 65/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 386s - loss: 0.8169 - acc: 0.7735 - val_loss: 0.7268 - val_acc: 0.7197\n",
      "Epoch 66/80\n",
      "200/200 [==============================] - 385s - loss: 0.8035 - acc: 0.7808 - val_loss: 0.5305 - val_acc: 0.8830\n",
      "Epoch 67/80\n",
      "200/200 [==============================] - 386s - loss: 0.7215 - acc: 0.7932 - val_loss: 0.4544 - val_acc: 0.8767\n",
      "Epoch 68/80\n",
      "200/200 [==============================] - 3460s - loss: 0.7570 - acc: 0.7786 - val_loss: 0.4562 - val_acc: 0.8574\n",
      "Epoch 69/80\n",
      "200/200 [==============================] - 397s - loss: 0.7068 - acc: 0.7981 - val_loss: 0.5179 - val_acc: 0.8278\n",
      "Epoch 70/80\n",
      "200/200 [==============================] - 396s - loss: 0.7991 - acc: 0.7812 - val_loss: 0.6965 - val_acc: 0.7996\n",
      "Epoch 71/80\n",
      "200/200 [==============================] - 391s - loss: 0.7609 - acc: 0.7716 - val_loss: 0.4839 - val_acc: 0.8534\n",
      "Epoch 72/80\n",
      "200/200 [==============================] - 389s - loss: 0.7479 - acc: 0.7967 - val_loss: 0.6749 - val_acc: 0.8839\n",
      "Epoch 73/80\n",
      "200/200 [==============================] - 387s - loss: 0.7503 - acc: 0.7832 - val_loss: 0.5469 - val_acc: 0.8475\n",
      "Epoch 74/80\n",
      "200/200 [==============================] - 386s - loss: 0.6945 - acc: 0.8027 - val_loss: 0.4829 - val_acc: 0.8552\n",
      "Epoch 75/80\n",
      "200/200 [==============================] - 384s - loss: 0.7735 - acc: 0.7892 - val_loss: 0.4271 - val_acc: 0.8978\n",
      "Epoch 76/80\n",
      "200/200 [==============================] - 385s - loss: 0.7652 - acc: 0.7786 - val_loss: 0.5607 - val_acc: 0.8063\n",
      "Epoch 77/80\n",
      "200/200 [==============================] - 388s - loss: 0.7742 - acc: 0.7793 - val_loss: 0.6874 - val_acc: 0.8013\n",
      "Epoch 78/80\n",
      "200/200 [==============================] - 389s - loss: 0.7914 - acc: 0.7837 - val_loss: 0.7215 - val_acc: 0.8439\n",
      "Epoch 79/80\n",
      "200/200 [==============================] - 421s - loss: 0.8142 - acc: 0.7808 - val_loss: 0.4875 - val_acc: 0.8453\n",
      "Epoch 80/80\n",
      "200/200 [==============================] - 385s - loss: 0.8138 - acc: 0.7809 - val_loss: 1.0507 - val_acc: 0.7413\n"
     ]
    }
   ],
   "source": [
    "'''This script is adapted from the blog post\n",
    "\n",
    "\"Building powerful image classification models using very little data\"\n",
    "\n",
    "from blog.keras.io.\n",
    "\n",
    "So that we have 1000 training examples for each class, and 300 validation examples for each class.\n",
    "\n",
    "In summary, this is our directory structure:\n",
    "\n",
    "```\n",
    "\n",
    "data/\n",
    "\n",
    "    train/\n",
    "\n",
    "        object1/\n",
    "\n",
    "            object1_1.jpg\n",
    "\n",
    "            object1_2.jpg\n",
    "\n",
    "            ...\n",
    "\n",
    "        object2/\n",
    "\n",
    "            object2_1.jpg\n",
    "\n",
    "            object2_2.jpg\n",
    "\n",
    "            ...\n",
    "\n",
    "    validation/\n",
    "\n",
    "        object1/\n",
    "\n",
    "            object1_1.jpg\n",
    "\n",
    "            object1_2.jpg\n",
    "\n",
    "            ...\n",
    "\n",
    "        object2/\n",
    "\n",
    "            object2_1.jpg\n",
    "\n",
    "            object2_2.jpg\n",
    "\n",
    "            ...\n",
    "\n",
    "```\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import keras\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "print('keras version:' + keras.__version__)\n",
    "print('tensorflow version:' + tensorflow.__version__)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dimensions of our images.\n",
    "\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = '/data/train'\n",
    "\n",
    "validation_data_dir = '/data/validation'\n",
    "\n",
    "nb_train_samples = 8000\n",
    "\n",
    "nb_validation_samples = 2400\n",
    "\n",
    "epochs = 80\n",
    "\n",
    "batch_size = 40\n",
    "\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "\n",
    "    input_shape = (3, img_width, img_height)\n",
    "\n",
    "else:\n",
    "    \n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(8))\n",
    "\n",
    "model.add(Activation('softmax')) #use sigmoid when binary and softmax when categorical\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "\n",
    "              optimizer='rmsprop',\n",
    "\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "\n",
    "    rescale=1. / 255,\n",
    "\n",
    "    shear_range=0.2,\n",
    "\n",
    "    zoom_range=0.2,\n",
    "\n",
    "    horizontal_flip=True)\n",
    "\n",
    "\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "\n",
    "# only rescaling\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "\n",
    "    train_data_dir,\n",
    "\n",
    "    target_size=(img_width, img_height),\n",
    "\n",
    "    batch_size=batch_size,\n",
    "\n",
    "    class_mode='categorical')\n",
    "\n",
    "\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "\n",
    "    validation_data_dir,\n",
    "\n",
    "    target_size=(img_width, img_height),\n",
    "\n",
    "    batch_size=batch_size,\n",
    "\n",
    "    class_mode='categorical')\n",
    "\n",
    "\n",
    "model.fit_generator(\n",
    "\n",
    "    train_generator,\n",
    "\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "\n",
    "    epochs=epochs,\n",
    "\n",
    "    validation_data=validation_generator,\n",
    "\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "\n",
    "model.save('detect_model.h5')\n",
    "model.save_weights('detect_weights.h5')"
   ]
  }
