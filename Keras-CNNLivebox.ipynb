{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras version:2.0.5\n",
      "tensorflow version:1.1.0\n",
      "Found 3221 images belonging to 8 classes.\n",
      "Found 446 images belonging to 8 classes.\n",
      "Epoch 1/80\n",
      "200/200 [==============================] - 534s - loss: 1.4966 - acc: 0.4584 - val_loss: 0.8381 - val_acc: 0.7601\n",
      "Epoch 2/80\n",
      "200/200 [==============================] - 378s - loss: 0.9810 - acc: 0.6672 - val_loss: 0.6020 - val_acc: 0.8466\n",
      "Epoch 3/80\n",
      "200/200 [==============================] - 379s - loss: 0.8214 - acc: 0.7216 - val_loss: 0.5014 - val_acc: 0.8686\n",
      "Epoch 4/80\n",
      "200/200 [==============================] - 375s - loss: 0.6818 - acc: 0.7726 - val_loss: 0.4003 - val_acc: 0.8897\n",
      "Epoch 5/80\n",
      "200/200 [==============================] - 375s - loss: 0.6187 - acc: 0.7923 - val_loss: 0.5620 - val_acc: 0.8332\n",
      "Epoch 6/80\n",
      "200/200 [==============================] - 383s - loss: 0.5647 - acc: 0.8079 - val_loss: 0.3463 - val_acc: 0.8937\n",
      "Epoch 7/80\n",
      "200/200 [==============================] - 380s - loss: 0.5538 - acc: 0.8157 - val_loss: 0.3808 - val_acc: 0.8924\n",
      "Epoch 8/80\n",
      "200/200 [==============================] - 376s - loss: 0.4926 - acc: 0.8379 - val_loss: 0.4063 - val_acc: 0.8830\n",
      "Epoch 9/80\n",
      "200/200 [==============================] - 374s - loss: 0.4931 - acc: 0.8353 - val_loss: 0.6504 - val_acc: 0.8305\n",
      "Epoch 10/80\n",
      "200/200 [==============================] - 373s - loss: 0.4908 - acc: 0.8421 - val_loss: 0.2839 - val_acc: 0.9152\n",
      "Epoch 11/80\n",
      "200/200 [==============================] - 375s - loss: 0.4839 - acc: 0.8429 - val_loss: 0.3576 - val_acc: 0.9166\n",
      "Epoch 12/80\n",
      "200/200 [==============================] - 372s - loss: 0.4496 - acc: 0.8564 - val_loss: 0.3725 - val_acc: 0.9166\n",
      "Epoch 13/80\n",
      "200/200 [==============================] - 370s - loss: 0.4650 - acc: 0.8508 - val_loss: 0.3444 - val_acc: 0.8924\n",
      "Epoch 14/80\n",
      "200/200 [==============================] - 435s - loss: 0.4552 - acc: 0.8544 - val_loss: 0.3948 - val_acc: 0.8843\n",
      "Epoch 15/80\n",
      "200/200 [==============================] - 399s - loss: 0.4451 - acc: 0.8538 - val_loss: 0.3527 - val_acc: 0.9197\n",
      "Epoch 16/80\n",
      "200/200 [==============================] - 384s - loss: 0.4450 - acc: 0.8578 - val_loss: 0.4226 - val_acc: 0.8879\n",
      "Epoch 17/80\n",
      "200/200 [==============================] - 386s - loss: 0.4473 - acc: 0.8622 - val_loss: 0.3736 - val_acc: 0.9058\n",
      "Epoch 18/80\n",
      "200/200 [==============================] - 394s - loss: 0.4828 - acc: 0.8489 - val_loss: 0.4234 - val_acc: 0.9170\n",
      "Epoch 19/80\n",
      "200/200 [==============================] - 393s - loss: 0.4828 - acc: 0.8437 - val_loss: 0.5429 - val_acc: 0.8677\n",
      "Epoch 20/80\n",
      "200/200 [==============================] - 393s - loss: 0.4764 - acc: 0.8528 - val_loss: 0.3644 - val_acc: 0.9000\n",
      "Epoch 21/80\n",
      "200/200 [==============================] - 390s - loss: 0.4880 - acc: 0.8456 - val_loss: 0.4986 - val_acc: 0.8413\n",
      "Epoch 22/80\n",
      "200/200 [==============================] - 389s - loss: 0.4849 - acc: 0.8507 - val_loss: 0.4075 - val_acc: 0.8870\n",
      "Epoch 23/80\n",
      "200/200 [==============================] - 392s - loss: 0.4930 - acc: 0.8461 - val_loss: 0.5528 - val_acc: 0.8700\n",
      "Epoch 24/80\n",
      "200/200 [==============================] - 392s - loss: 0.4900 - acc: 0.8478 - val_loss: 0.3920 - val_acc: 0.8812\n",
      "Epoch 25/80\n",
      "200/200 [==============================] - 448s - loss: 0.5253 - acc: 0.8387 - val_loss: 0.4896 - val_acc: 0.9036\n",
      "Epoch 26/80\n",
      "200/200 [==============================] - 441s - loss: 0.5078 - acc: 0.8451 - val_loss: 0.5168 - val_acc: 0.8659\n",
      "Epoch 27/80\n",
      "200/200 [==============================] - 429s - loss: 0.5028 - acc: 0.8429 - val_loss: 0.5474 - val_acc: 0.9000\n",
      "Epoch 28/80\n",
      "200/200 [==============================] - 400s - loss: 0.5204 - acc: 0.8409 - val_loss: 0.5002 - val_acc: 0.8879\n",
      "Epoch 29/80\n",
      "200/200 [==============================] - 415s - loss: 0.5621 - acc: 0.8373 - val_loss: 0.3978 - val_acc: 0.9197\n",
      "Epoch 30/80\n",
      "200/200 [==============================] - 400s - loss: 0.5466 - acc: 0.8333 - val_loss: 0.3897 - val_acc: 0.9040\n",
      "Epoch 31/80\n",
      "200/200 [==============================] - 389s - loss: 0.5888 - acc: 0.8252 - val_loss: 0.3921 - val_acc: 0.8901\n",
      "Epoch 32/80\n",
      "200/200 [==============================] - 390s - loss: 0.5128 - acc: 0.8446 - val_loss: 0.4449 - val_acc: 0.8780\n",
      "Epoch 33/80\n",
      "200/200 [==============================] - 391s - loss: 0.5508 - acc: 0.8413 - val_loss: 0.3812 - val_acc: 0.9094\n",
      "Epoch 34/80\n",
      "200/200 [==============================] - 391s - loss: 0.5579 - acc: 0.8394 - val_loss: 0.5044 - val_acc: 0.8525\n",
      "Epoch 35/80\n",
      "200/200 [==============================] - 393s - loss: 0.5164 - acc: 0.8458 - val_loss: 0.4103 - val_acc: 0.8978\n",
      "Epoch 36/80\n",
      "200/200 [==============================] - 395s - loss: 0.5358 - acc: 0.8340 - val_loss: 0.5485 - val_acc: 0.8359\n",
      "Epoch 37/80\n",
      "200/200 [==============================] - 392s - loss: 0.5982 - acc: 0.8340 - val_loss: 0.3698 - val_acc: 0.9036\n",
      "Epoch 38/80\n",
      "200/200 [==============================] - 390s - loss: 0.5545 - acc: 0.8340 - val_loss: 0.3932 - val_acc: 0.8942\n",
      "Epoch 39/80\n",
      "200/200 [==============================] - 390s - loss: 0.6153 - acc: 0.8280 - val_loss: 0.8459 - val_acc: 0.7229\n",
      "Epoch 40/80\n",
      "200/200 [==============================] - 393s - loss: 0.5924 - acc: 0.8278 - val_loss: 0.5747 - val_acc: 0.9022\n",
      "Epoch 41/80\n",
      "200/200 [==============================] - 390s - loss: 0.6314 - acc: 0.8124 - val_loss: 0.4218 - val_acc: 0.9108\n",
      "Epoch 42/80\n",
      "200/200 [==============================] - 393s - loss: 0.5688 - acc: 0.8316 - val_loss: 0.6280 - val_acc: 0.8735\n",
      "Epoch 43/80\n",
      "200/200 [==============================] - 401s - loss: 0.5970 - acc: 0.8298 - val_loss: 0.3696 - val_acc: 0.8991\n",
      "Epoch 44/80\n",
      "200/200 [==============================] - 445s - loss: 0.6203 - acc: 0.8192 - val_loss: 0.5071 - val_acc: 0.8803\n",
      "Epoch 45/80\n",
      "200/200 [==============================] - 514s - loss: 0.6066 - acc: 0.8152 - val_loss: 0.4696 - val_acc: 0.8709\n",
      "Epoch 46/80\n",
      "200/200 [==============================] - 373s - loss: 0.5947 - acc: 0.8350 - val_loss: 0.7322 - val_acc: 0.8408\n",
      "Epoch 47/80\n",
      "200/200 [==============================] - 373s - loss: 0.6034 - acc: 0.8167 - val_loss: 0.3603 - val_acc: 0.8874\n",
      "Epoch 48/80\n",
      "200/200 [==============================] - 375s - loss: 0.6910 - acc: 0.8085 - val_loss: 0.5901 - val_acc: 0.8408\n",
      "Epoch 49/80\n",
      "200/200 [==============================] - 371s - loss: 0.6961 - acc: 0.8015 - val_loss: 0.4755 - val_acc: 0.8610\n",
      "Epoch 50/80\n",
      "200/200 [==============================] - 369s - loss: 0.6402 - acc: 0.8207 - val_loss: 0.4857 - val_acc: 0.8350\n",
      "Epoch 51/80\n",
      "200/200 [==============================] - 434s - loss: 0.6332 - acc: 0.8139 - val_loss: 0.5205 - val_acc: 0.8659\n",
      "Epoch 52/80\n",
      "200/200 [==============================] - 468s - loss: 0.6446 - acc: 0.8181 - val_loss: 0.4186 - val_acc: 0.9121\n",
      "Epoch 53/80\n",
      "200/200 [==============================] - 483s - loss: 0.6935 - acc: 0.8020 - val_loss: 0.5016 - val_acc: 0.9108\n",
      "Epoch 54/80\n",
      "200/200 [==============================] - 504s - loss: 0.6274 - acc: 0.8183 - val_loss: 0.8133 - val_acc: 0.8547\n",
      "Epoch 55/80\n",
      "200/200 [==============================] - 424s - loss: 0.6692 - acc: 0.8070 - val_loss: 0.6197 - val_acc: 0.7982\n",
      "Epoch 56/80\n",
      "200/200 [==============================] - 527s - loss: 0.6973 - acc: 0.8099 - val_loss: 0.5542 - val_acc: 0.8516\n",
      "Epoch 57/80\n",
      "200/200 [==============================] - 461s - loss: 0.7072 - acc: 0.7951 - val_loss: 1.0594 - val_acc: 0.8018\n",
      "Epoch 58/80\n",
      "200/200 [==============================] - 404s - loss: 0.6727 - acc: 0.8030 - val_loss: 1.2645 - val_acc: 0.7103\n",
      "Epoch 59/80\n",
      "200/200 [==============================] - 413s - loss: 0.7098 - acc: 0.7998 - val_loss: 0.6783 - val_acc: 0.8570\n",
      "Epoch 60/80\n",
      "200/200 [==============================] - 426s - loss: 0.7322 - acc: 0.7944 - val_loss: 0.8256 - val_acc: 0.7350\n",
      "Epoch 61/80\n",
      "200/200 [==============================] - 453s - loss: 0.7495 - acc: 0.7803 - val_loss: 0.5555 - val_acc: 0.8946\n",
      "Epoch 62/80\n",
      "200/200 [==============================] - 435s - loss: 0.7485 - acc: 0.7935 - val_loss: 0.7179 - val_acc: 0.8233\n",
      "Epoch 63/80\n",
      "200/200 [==============================] - 565s - loss: 0.8119 - acc: 0.7741 - val_loss: 0.4525 - val_acc: 0.8901\n",
      "Epoch 64/80\n",
      "200/200 [==============================] - 399s - loss: 0.7377 - acc: 0.7867 - val_loss: 0.5250 - val_acc: 0.8260\n",
      "Epoch 65/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 386s - loss: 0.8169 - acc: 0.7735 - val_loss: 0.7268 - val_acc: 0.7197\n",
      "Epoch 66/80\n",
      "200/200 [==============================] - 385s - loss: 0.8035 - acc: 0.7808 - val_loss: 0.5305 - val_acc: 0.8830\n",
      "Epoch 67/80\n",
      "200/200 [==============================] - 386s - loss: 0.7215 - acc: 0.7932 - val_loss: 0.4544 - val_acc: 0.8767\n",
      "Epoch 68/80\n",
      "200/200 [==============================] - 3460s - loss: 0.7570 - acc: 0.7786 - val_loss: 0.4562 - val_acc: 0.8574\n",
      "Epoch 69/80\n",
      "200/200 [==============================] - 397s - loss: 0.7068 - acc: 0.7981 - val_loss: 0.5179 - val_acc: 0.8278\n",
      "Epoch 70/80\n",
      "200/200 [==============================] - 396s - loss: 0.7991 - acc: 0.7812 - val_loss: 0.6965 - val_acc: 0.7996\n",
      "Epoch 71/80\n",
      "200/200 [==============================] - 391s - loss: 0.7609 - acc: 0.7716 - val_loss: 0.4839 - val_acc: 0.8534\n",
      "Epoch 72/80\n",
      "200/200 [==============================] - 389s - loss: 0.7479 - acc: 0.7967 - val_loss: 0.6749 - val_acc: 0.8839\n",
      "Epoch 73/80\n",
      "200/200 [==============================] - 387s - loss: 0.7503 - acc: 0.7832 - val_loss: 0.5469 - val_acc: 0.8475\n",
      "Epoch 74/80\n",
      "200/200 [==============================] - 386s - loss: 0.6945 - acc: 0.8027 - val_loss: 0.4829 - val_acc: 0.8552\n",
      "Epoch 75/80\n",
      "200/200 [==============================] - 384s - loss: 0.7735 - acc: 0.7892 - val_loss: 0.4271 - val_acc: 0.8978\n",
      "Epoch 76/80\n",
      "200/200 [==============================] - 385s - loss: 0.7652 - acc: 0.7786 - val_loss: 0.5607 - val_acc: 0.8063\n",
      "Epoch 77/80\n",
      "200/200 [==============================] - 388s - loss: 0.7742 - acc: 0.7793 - val_loss: 0.6874 - val_acc: 0.8013\n",
      "Epoch 78/80\n",
      "200/200 [==============================] - 389s - loss: 0.7914 - acc: 0.7837 - val_loss: 0.7215 - val_acc: 0.8439\n",
      "Epoch 79/80\n",
      "200/200 [==============================] - 421s - loss: 0.8142 - acc: 0.7808 - val_loss: 0.4875 - val_acc: 0.8453\n",
      "Epoch 80/80\n",
      "200/200 [==============================] - 385s - loss: 0.8138 - acc: 0.7809 - val_loss: 1.0507 - val_acc: 0.7413\n"
     ]
    }
   ],
   "source": [
    "'''This script is adapted from the blog post\n",
    "\n",
    "\"Building powerful image classification models using very little data\"\n",
    "\n",
    "from blog.keras.io.\n",
    "\n",
    "So that we have 1000 training examples for each class, and 400 validation examples for each class.\n",
    "\n",
    "In summary, this is our directory structure:\n",
    "\n",
    "```\n",
    "\n",
    "data/\n",
    "\n",
    "    train/\n",
    "\n",
    "        livebox_play/\n",
    "\n",
    "            livebox_1.jpg\n",
    "\n",
    "            livebox_2.jpg\n",
    "\n",
    "            ...\n",
    "\n",
    "        other/\n",
    "\n",
    "            livebox_1.jpg\n",
    "\n",
    "            livebox_2.jpg\n",
    "\n",
    "            ...\n",
    "\n",
    "    validation/\n",
    "\n",
    "        livebox_play/\n",
    "\n",
    "            livebox_1.jpg\n",
    "\n",
    "            livebox_2.jpg\n",
    "\n",
    "            ...\n",
    "\n",
    "        other/\n",
    "\n",
    "            other_1.jpg\n",
    "\n",
    "            other_2.jpg\n",
    "\n",
    "            ...\n",
    "\n",
    "```\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import keras\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "print('keras version:' + keras.__version__)\n",
    "print('tensorflow version:' + tensorflow.__version__)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dimensions of our images.\n",
    "\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = '/home/comedelobelle/Documents/Environment/data/train'\n",
    "\n",
    "validation_data_dir = '/home/comedelobelle/Documents/Environment/data/validation'\n",
    "\n",
    "nb_train_samples = 8000 #2700\n",
    "\n",
    "nb_validation_samples = 2400#600\n",
    "\n",
    "epochs = 80\n",
    "\n",
    "batch_size = 40\n",
    "\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "\n",
    "    input_shape = (3, img_width, img_height)\n",
    "\n",
    "else:\n",
    "    \n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(8))\n",
    "\n",
    "model.add(Activation('softmax')) #use sigmoid when binary and softmax when categorical\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "\n",
    "              optimizer='rmsprop',\n",
    "\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "\n",
    "    rescale=1. / 255,\n",
    "\n",
    "    shear_range=0.2,\n",
    "\n",
    "    zoom_range=0.2,\n",
    "\n",
    "    horizontal_flip=True)\n",
    "\n",
    "\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "\n",
    "# only rescaling\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "\n",
    "    train_data_dir,\n",
    "\n",
    "    target_size=(img_width, img_height),\n",
    "\n",
    "    batch_size=batch_size,\n",
    "\n",
    "    class_mode='categorical')\n",
    "\n",
    "\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "\n",
    "    validation_data_dir,\n",
    "\n",
    "    target_size=(img_width, img_height),\n",
    "\n",
    "    batch_size=batch_size,\n",
    "\n",
    "    class_mode='categorical')\n",
    "\n",
    "\n",
    "model.fit_generator(\n",
    "\n",
    "    train_generator,\n",
    "\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "\n",
    "    epochs=epochs,\n",
    "\n",
    "    validation_data=validation_generator,\n",
    "\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "\n",
    "model.save('discriminate_model.h5')\n",
    "model.save_weights('discriminate_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras version:2.0.5\n",
      "tensorflow version:1.1.0\n",
      "1/1 [==============================] - 0s\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Livebox 2 set test\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 2\n",
      "32\n",
      "0\n",
      "0\n",
      "\n",
      "Taux d'erreur = 0 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Livebox 4 set test\n",
      "[[ 0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 4\n",
      "[[ 0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 4\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  1.  0.  0.  0.  0.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 4\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 4\n",
      "[[ 0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 4\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  1.]]\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 4\n",
      "[[ 0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 4\n",
      "[[ 0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 4\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  1.  0.  0.  0.  0.  0.  0.]]\n",
      "[[ 0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 4\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 4\n",
      "[[ 0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 4\n",
      "[[ 0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 4\n",
      "[[ 0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 4\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 4\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 4\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 4\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 4\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 4\n",
      "[[ 0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 4\n",
      "[[ 0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 4\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 4\n",
      "[[ 0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 4\n",
      "[[ 0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 4\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 4\n",
      "[[ 0.  1.  0.  0.  0.  0.  0.  0.]]\n",
      "[[ 0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "C'est une Livebox 4\n",
      "0\n",
      "25\n",
      "27\n",
      "\n",
      "Taux d'erreur = 0 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Livebox Play set test\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  1.]]\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  1.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  1.]]\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  1.]]\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  1.]]\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  1.]]\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  1.]]\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  1.]]\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  1.]]\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "C'est une Livebox Play\n",
      "[[ 0.16957743  0.15669265  0.09717064  0.0731681   0.03393853  0.13745792\n",
      "   0.19020861  0.14178605]]\n",
      "0\n",
      "0\n",
      "36\n",
      "0\n",
      "\n",
      "Taux d'erreur = 0 %\n"
     ]
    }
   ],
   "source": [
    "#run the model for Livebox\n",
    "\n",
    "import keras\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import glob\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "from keras.backend import tf as ktf\n",
    "\n",
    "print('keras version:' + keras.__version__)\n",
    "\n",
    "print('tensorflow version:' + tensorflow.__version__)\n",
    "\n",
    "model = load_model('discriminate_model.h5') # loading model and weights for the prediction\n",
    "model.load_weights('discriminate_weights.h5')\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "\n",
    "              optimizer='rmsprop',\n",
    "\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Confirm on one single image from any validation set\n",
    "img = load_img('/home/comedelobelle/Documents/Environment/data/fakecheck.jpg') # this is a PIL image\n",
    "\n",
    "x = img_to_array(img)  \n",
    "imgresized = cv2.resize(x,(150,150)) # this is a Numpy array with shape (3, 150, 150)\n",
    "\n",
    "imgresized = imgresized[np.newaxis,...] # dimension added to fit input size\n",
    "predo = model.predict_proba(imgresized,1)\n",
    "print(predo)\n",
    "\n",
    "#Confirm on Livebox 2 validation set\n",
    "print('\\n\\n\\n\\nLivebox 2 set test')\n",
    "\n",
    "imageFolderPath2 = '/home/comedelobelle/Documents/Environment/data/validation/livebox_2'\n",
    "imagePath2 = glob.glob(imageFolderPath2 + '/*.jpg')\n",
    "'''im_array2 = np.array( [cv2.resize(np.array(Image.open(imagePath2[i])), (150,150)) for i in range(len(imagePath2))] )\n",
    "predo2 = model.predict_proba(im_array2)\n",
    "print(predo2)'''\n",
    "live2 = 0\n",
    "live4 = 0\n",
    "livePlay = 0\n",
    "\n",
    "for k in range(len(imagePath2)):\n",
    "    try: # print the category using the model.predict output\n",
    "        im_array2 = np.array([cv2.resize(np.array(Image.open(imagePath2[k])), (150,150))])\n",
    "        predo2 = model.predict(im_array2)\n",
    "        print(predo2)\n",
    "        itemindex = np.flatnonzero(predo2==1)\n",
    "        if itemindex == 2:\n",
    "            live2 += 1\n",
    "            print('C\\'est une Livebox 2')\n",
    "        elif itemindex == 3:\n",
    "            live4 += 1\n",
    "            print('C\\'est une Livebox 4')\n",
    "        elif itemindex == 4:\n",
    "            livePlay += 1\n",
    "            print('C\\'est une Livebox Play')\n",
    "    except IndexError: # except the error occurring when no solid prediction was made\n",
    "        print('Aucune prédiction certaine\\nDonnées d\\'entrainement du modèle insuffisantes')\n",
    "\n",
    "print(live2)\n",
    "print(live4)\n",
    "print(livePlay)\n",
    "\n",
    "taux2 = ((live4 + livePlay)/(live2+live4+livePlay))*100\n",
    "taux2 = str(taux2)\n",
    "print('\\nTaux d\\'erreur = ' +taux2+ ' %')\n",
    "\n",
    "#Confirm on Livebox 4 validation set\n",
    "print('\\n\\n\\n\\nLivebox 4 set test')\n",
    "\n",
    "imageFolderPath4 = '/home/comedelobelle/Documents/Environment/data/validation/livebox_4'\n",
    "imagePath4 = glob.glob(imageFolderPath4 + '/*.jpg')\n",
    "live2 = 0\n",
    "live4 = 0\n",
    "livePlay = 0\n",
    "count=0\n",
    "\n",
    "for k in range(len(imagePath4)):\n",
    "    count += 1\n",
    "    try: # print the category using the model.predict output\n",
    "        im_array4 = np.array([cv2.resize(np.array(Image.open(imagePath4[k])), (150,150))])\n",
    "        predo4 = model.predict(im_array4)\n",
    "        print(predo4)\n",
    "        itemindex = np.flatnonzero(predo4==1)\n",
    "        if itemindex == 2:\n",
    "            int live2 += 1\n",
    "            print('C\\'est une Livebox 2')\n",
    "        elif itemindex == 3:\n",
    "            live4 += 1\n",
    "            print('C\\'est une Livebox 4')\n",
    "        elif itemindex == 4:\n",
    "            livePlay += 1\n",
    "            print('C\\'est une Livebox Play')\n",
    "    except IndexError: # except the error occurring when no solid prediction was made\n",
    "        print('Aucune prédiction certaine\\nDonnées d\\'entrainement du modèle insuffisantes')\n",
    "\n",
    "print(live2)\n",
    "print(live4)\n",
    "print(livePlay)       \n",
    "\n",
    "taux4 = ((live2 + livePlay)/count)*100\n",
    "taux4 = str(taux4)\n",
    "print('\\nTaux d\\'erreur = ' +taux4+ ' %')\n",
    "\n",
    "#Confirm on Livebox Play validation set\n",
    "print('\\n\\n\\n\\nLivebox Play set test')\n",
    "\n",
    "imageFolderPathPlay = '/home/comedelobelle/Documents/Environment/data/validation/livebox_play'\n",
    "imagePathPlay = glob.glob(imageFolderPathPlay + '/*.jpg')\n",
    "live2 = 0\n",
    "live4 = 0\n",
    "livePlay = 0\n",
    "count=0\n",
    "for k in range(len(imagePathPlay)):\n",
    "    count += 1\n",
    "    try: # print the category using the model.predict output\n",
    "        im_arrayPlay = np.array([cv2.resize(np.array(Image.open(imagePathPlay[k])), (150,150))])\n",
    "        predoPlay = model.predict(im_arrayPlay)\n",
    "        print(predoPlay)\n",
    "        itemindex = np.flatnonzero(predoPlay==1)\n",
    "        if itemindex == 2:\n",
    "            live2 += 1\n",
    "            print('C\\'est une Livebox 2')\n",
    "        elif itemindex == 3:\n",
    "            live4 += 1\n",
    "            print('C\\'est une Livebox 4')\n",
    "        elif itemindex == 4:\n",
    "            livePlay += 1\n",
    "            print('C\\'est une Livebox Play')\n",
    "    except IndexError: # except the error occurring when no solid prediction was made\n",
    "        print('Aucune prédiction certaine\\nDonnées d\\'entrainement du modèle insuffisantes')\n",
    "\n",
    "print(live2)\n",
    "print(live4)\n",
    "print(livePlay)\n",
    "\n",
    "tauxPlay = ((live2+live4)/count)*100\n",
    "print tauxPlay\n",
    "tauxPlay = str(tauxPlay)\n",
    "print('\\nTaux d\\'erreur = ' +tauxPlay+ ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import coremltools\n",
    "\n",
    "coreml_model = coremltools.converters.keras.convert('fool-enhanced_model.h5',\n",
    "                                                    \n",
    "                                                    input_names = 'image',\n",
    "                                                    \n",
    "                                                    image_input_names = 'image',\n",
    "                                                    \n",
    "                                                    class_labels = ['Livebox 2', 'Livebox 4', 'Livebox Play'])\n",
    "coreml_model.save(\"livebox_recV3.mlmodel\")\n",
    "\n",
    "coreml_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Android Compiler model + weights\n",
    "\n",
    "import keras\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "print('keras version:' + keras.__version__)\n",
    "print('tensorflow version:' + tensorflow.__version__)\n",
    "\n",
    "from keras.layers import InputLayer\n",
    "\n",
    "input = tf.placeholder(tf.float32, name='input')\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(InputLayer(input_tensor=input))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(3))\n",
    "\n",
    "model.add(Activation('softmax')) #use sigmoid when binary and softmax when categorical\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "\n",
    "              optimizer='rmsprop',\n",
    "\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Android adaptation from the original program\n",
    "\n",
    "'''This script is adapted from the blog post\n",
    "\n",
    "\"Building powerful image classification models using very little data\"\n",
    "\n",
    "from blog.keras.io.\n",
    "\n",
    "So that we have 1000 training examples for each class, and 400 validation examples for each class.\n",
    "\n",
    "In summary, this is our directory structure:\n",
    "\n",
    "```\n",
    "\n",
    "data/\n",
    "\n",
    "    train/\n",
    "\n",
    "        livebox_play/\n",
    "\n",
    "            livebox_1.jpg\n",
    "\n",
    "            livebox_2.jpg\n",
    "\n",
    "            ...\n",
    "\n",
    "        other/\n",
    "\n",
    "            livebox_1.jpg\n",
    "\n",
    "            livebox_2.jpg\n",
    "\n",
    "            ...\n",
    "\n",
    "    validation/\n",
    "\n",
    "        livebox_play/\n",
    "\n",
    "            livebox_1.jpg\n",
    "\n",
    "            livebox_2.jpg\n",
    "\n",
    "            ...\n",
    "\n",
    "        other/\n",
    "\n",
    "            other_1.jpg\n",
    "\n",
    "            other_2.jpg\n",
    "\n",
    "            ...\n",
    "\n",
    "```\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import keras\n",
    "\n",
    "import tensorflow\n",
    "sess=tensorflow.Session()\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.layers import InputLayer\n",
    "\n",
    "print('keras version:' + keras.__version__)\n",
    "print('tensorflow version:' + tensorflow.__version__)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dimensions of our images.\n",
    "\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "\n",
    "\n",
    "train_data_dir = '/home/comedelobelle/Documents/Environment/data/train'\n",
    "\n",
    "validation_data_dir = '/home/comedelobelle/Documents/Environment/data/validation'\n",
    "\n",
    "nb_train_samples = 120 #2700\n",
    "\n",
    "nb_validation_samples = 24 #600\n",
    "\n",
    "epochs = 5 #50\n",
    "\n",
    "batch_size = 15 #30\n",
    "\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "\n",
    "    input_shape = (3, img_width, img_height)\n",
    "    input_shapep = (0, 3, img_width, img_height)\n",
    "\n",
    "else:\n",
    "    \n",
    "    input_shape = (img_width, img_height, 3)\n",
    "    input_shapep = (0, img_width, img_height, 3)\n",
    "    \n",
    "\n",
    "#inputp = tensorflow.placeholder(tensorflow.float32, shape=input_shapep) #android test\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#model.add(InputLayer(input_tensor=inputp, input_shape=input_shape)) #android test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(3))\n",
    "\n",
    "model.add(Activation('softmax')) #use sigmoid when binary and softmax when categorical\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "\n",
    "              optimizer='rmsprop',\n",
    "\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "\n",
    "    rescale=1. / 255,\n",
    "\n",
    "    shear_range=0.2,\n",
    "\n",
    "    zoom_range=0.2,\n",
    "\n",
    "    horizontal_flip=True)\n",
    "\n",
    "\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "\n",
    "# only rescaling\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "\n",
    "    train_data_dir,\n",
    "\n",
    "    target_size=(img_width, img_height),\n",
    "\n",
    "    batch_size=batch_size,\n",
    "\n",
    "    class_mode='categorical')\n",
    "\n",
    "\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "\n",
    "    validation_data_dir,\n",
    "\n",
    "    target_size=(img_width, img_height),\n",
    "\n",
    "    batch_size=batch_size,\n",
    "\n",
    "    class_mode='categorical')\n",
    "\n",
    "\n",
    "model.fit_generator(\n",
    "\n",
    "    train_generator,\n",
    "\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "\n",
    "    epochs=epochs,\n",
    "\n",
    "    validation_data=validation_generator,\n",
    "\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Export to Tensorflow\n",
    "from tensorflow.python.saved_model import builder, tag_constants, signature_def_utils, loader, utils\n",
    "\n",
    "sess = K.get_session()\n",
    "tensorflow.initialize_all_variables().run(session=sess)\n",
    "saver = builder.SavedModelBuilder('/home/comedelobelle/Documents/Environment/TFmodelAnd2/')\n",
    "signature = signature_def_utils.build_signature_def(inputs={'conv2d': utils.build_tensor_info(model.input)},\n",
    "                                              outputs={'outputs': utils.build_tensor_info(model.output)},\n",
    "                                              method_name='tensorflow/serving/predict')\n",
    "saver.add_meta_graph_and_variables(sess=sess, tags=[tag_constants.SERVING],\n",
    "                                             signature_def_map={'predict': signature})\n",
    "saver.save()\n",
    "\n",
    "model.save('androidtest_model.h5')\n",
    "model.save_weights('androidtest_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License.\n",
    "\"\"\"Convolutional Neural Network Estimator for MNIST, built with tf.layers.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "\n",
    "def cnn_model_fn(features, labels, mode):\n",
    "  \"\"\"Model function for CNN.\"\"\"\n",
    "  # Input Layer\n",
    "  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "  # Livebox images are 150x150 pixels, and have three color channel\n",
    "  input_layer = tf.reshape(features, [-1, 150, 150, 3], name='inputlayer')\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "  # Computes 32 features using a 3x3 filter with ReLU activation.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 150, 150, 3]\n",
    "  # Output Tensor Shape: [batch_size, 150, 150, 32]\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #1\n",
    "  # First max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 150, 150, 32]\n",
    "  # Output Tensor Shape: [batch_size, 75, 75, 32]\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "  # Convolutional Layer #2\n",
    "  # Computes 32 features using a 3x3 filter with ReLU activation.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 150, 150, 3]\n",
    "  # Output Tensor Shape: [batch_size, 150, 150, 32]\n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=32,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #2\n",
    "  # First max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 150, 150, 32]\n",
    "  # Output Tensor Shape: [batch_size, 75, 75, 32]\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Convolutional Layer #3\n",
    "  # Computes 64 features using a 3x3 filter.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 75, 75, 32]\n",
    "  # Output Tensor Shape: [batch_size, 75, 75, 64]\n",
    "  conv3 = tf.layers.conv2d(\n",
    "      inputs=pool2,\n",
    "      filters=64,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #3\n",
    "  # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 75, 75, 64]\n",
    "  # Output Tensor Shape: [batch_size, 37, 37, 64]\n",
    "  pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Flatten tensor into a batch of vectors\n",
    "  # Input Tensor Shape: [batch_size, 37, 37, 64]\n",
    "  # Output Tensor Shape: [batch_size, 37 * 37 * 64]\n",
    "  pool3_flat = tf.reshape(pool3, [-1, 37 * 37 * 64])\n",
    "\n",
    "  # Dense Layer\n",
    "  # Densely connected layer with 64 neurons\n",
    "  # Input Tensor Shape: [batch_size, 37 * 37 * 64]\n",
    "  # Output Tensor Shape: [batch_size, 64]\n",
    "  dense = tf.layers.dense(inputs=pool3_flat, units=64, activation=tf.nn.relu)\n",
    "\n",
    "  # Add dropout operation; 0.5 probability that element will be kept\n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.5, training=mode == learn.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits layer\n",
    "  # Input Tensor Shape: [batch_size, 64]\n",
    "  # Output Tensor Shape: [batch_size, 3]\n",
    "  logits = tf.layers.dense(inputs=dropout, units=3)\n",
    "\n",
    "  loss = None\n",
    "  train_op = None\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "  if mode != learn.ModeKeys.INFER:\n",
    "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "        onehot_labels=onehot_labels, logits=logits)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == learn.ModeKeys.TRAIN:\n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "        loss=loss,\n",
    "        global_step=tf.contrib.framework.get_global_step(),\n",
    "        learning_rate=0.001,\n",
    "        optimizer=\"SGD\")\n",
    "\n",
    "  # Generate Predictions\n",
    "  predictions = {\n",
    "      \"classes\": tf.argmax(\n",
    "          input=logits, axis=1),\n",
    "      \"probabilities\": tf.nn.softmax(\n",
    "          logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "\n",
    "  # Return a ModelFnOps object\n",
    "  return model_fn_lib.ModelFnOps(\n",
    "      mode=mode, predictions=predictions, loss=loss, train_op=train_op)\n",
    "\n",
    "#Load custom train dataset for Livebox\n",
    "\n",
    "\n",
    "\n",
    "def main(unused_argv):\n",
    "  # Load training and eval data\n",
    "  train_data = mnist.train.images  # Returns np.array\n",
    "  train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "  eval_data = mnist.test.images  # Returns np.array\n",
    "  eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "  # Create the Estimator\n",
    "  mnist_classifier = learn.Estimator(\n",
    "      model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")\n",
    "\n",
    "  # Set up logging for predictions\n",
    "  # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "  tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "  logging_hook = tf.train.LoggingTensorHook(\n",
    "      tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "  # Train the model\n",
    "  mnist_classifier.fit(\n",
    "      x=train_data,\n",
    "      y=train_labels,\n",
    "      batch_size=100,\n",
    "      steps=20000,\n",
    "      monitors=[logging_hook])\n",
    "\n",
    "  # Configure the accuracy metric for evaluation\n",
    "  metrics = {\n",
    "      \"accuracy\":\n",
    "          learn.MetricSpec(\n",
    "              metric_fn=tf.metrics.accuracy, prediction_key=\"classes\"),\n",
    "  }\n",
    "\n",
    "  # Evaluate the model and print results\n",
    "  eval_results = mnist_classifier.evaluate(\n",
    "      x=eval_data, y=eval_labels, metrics=metrics)\n",
    "  print(eval_results)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "livebox2train = [f for f in listdir('./data/train/livebox_2') if isfile(join('./data/train/livebox_2', f))]\n",
    "livebox2train_queue = tf.train.string_input_producer(livebox2train)\n",
    "\n",
    "reader = tf.WholeFileReader()\n",
    "livebox2train, content2 = reader.read(livebox2train_queue)\n",
    "image2 = tf.image.decode_jpeg(content2, channels=3)\n",
    "image2 = tf.cast(image2, tf.float32)\n",
    "resized_image2 = tf.image.resize_images(image2, [150, 150])\n",
    "\n",
    "image2_batch = tf.train.batch([resized_image2, 'livebox_2'], batch_size=8)\n",
    "\n",
    "livebox4train = [f for f in listdir('./data/train/livebox_4') if isfile(join('./data/train/livebox_4', f))]\n",
    "livebox4train_queue = tf.train.string_input_producer(livebox4train)\n",
    "\n",
    "livebox4train, content4 = reader.read(livebox4train_queue)\n",
    "image4 = tf.image.decode_jpeg(content4, channels=3)\n",
    "image4 = tf.cast(image4, tf.float32)\n",
    "resized_image4 = tf.image.resize_images(image4, [150, 150])\n",
    "\n",
    "image4_batch = tf.train.batch([resized_image4, 'livebox_4'], batch_size=8)\n",
    "\n",
    "liveboxPlaytrain = [f for f in listdir('./data/train/livebox_play') if isfile(join('./data/train/livebox_play', f))]\n",
    "liveboxPlaytrain_queue = tf.train.string_input_producer(liveboxPlaytrain)\n",
    "\n",
    "liveboxPlaytrain, contentPlay = reader.read(liveboxPlaytrain_queue)\n",
    "imagePlay = tf.image.decode_jpeg(contentPlay, channels=3)\n",
    "imagePlay = tf.cast(imagePlay, tf.float32)\n",
    "resized_imagePlay = tf.image.resize_images(imagePlay, [150, 150])\n",
    "\n",
    "imagePlay_batch = tf.train.batch([resized_imagePlay, 'livebox_play'], batch_size=8)\n",
    "print(imagePlay_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
